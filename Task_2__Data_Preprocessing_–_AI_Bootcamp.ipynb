{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L982FdumDCVn"
      },
      "source": [
        "# Task 2: Data Preprocessing for Machine Learning – AI Bootcamp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYXOL4aRs33g"
      },
      "source": [
        "Download Titanic Dataset here: https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv\n",
        "\n",
        "#### About this file\n",
        "\n",
        "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
        "\n",
        "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone on board, resulting in the death of 1502 out of 2224 passengers and crew.\n",
        "\n",
        "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
        "\n",
        "In this challenge, we ask you to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk9AwRFXDO6n"
      },
      "source": [
        "## Section 1: Data Loading & Exploration"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_and_explore_data(file_path):\n",
        "    \"\"\"\n",
        "    Loads data from a CSV file into a Pandas DataFrame and performs basic exploration.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The path to the CSV file.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: The loaded DataFrame.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        print(\"Data loaded successfully!\")\n",
        "        print(\"\\nFirst 5 rows of the DataFrame:\")\n",
        "        print(df.head())\n",
        "        print(\"\\nInformation about the DataFrame:\")\n",
        "        print(df.info())\n",
        "        print(\"\\nDescriptive statistics of numerical columns:\")\n",
        "        print(df.describe())\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at '{file_path}'\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace 'your_data.csv' with the actual path to your CSV file\n",
        "    file_path = 'your_data.csv'\n",
        "\n",
        "    # Create a sample CSV file for demonstration if 'your_data.csv' doesn't exist\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            pass\n",
        "    except FileNotFoundError:\n",
        "        data = {'col1': [1, 2, 3, 4, 5],\n",
        "                'col2': ['A', 'B', 'A', 'C', 'B'],\n",
        "                'col3': [10.5, 20.3, 15.0, 22.1, 18.7]}\n",
        "        sample_df = pd.DataFrame(data)\n",
        "        sample_df.to_csv(file_path, index=False)\n",
        "        print(f\"Created a sample '{file_path}' for demonstration. Please replace it with your actual data file.\")\n",
        "\n",
        "    loaded_df = load_and_explore_data(file_path)\n",
        "\n",
        "    if loaded_df is not None:\n",
        "        print(\"\\nShape of the DataFrame:\", loaded_df.shape)\n",
        "        print(\"\\nNumber of missing values per column:\")\n",
        "        print(loaded_df.isnull().sum())\n",
        "        print(\"\\nUnique values in categorical columns:\")\n",
        "        for col in loaded_df.select_dtypes(include='object').columns:\n",
        "            print(f\"- {col}: {loaded_df[col].nunique()} unique values ({loaded_df[col].unique()})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtMjoek_z5uC",
        "outputId": "124fdbf4-edd0-4325-b247-4407a39d631d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a sample 'your_data.csv' for demonstration. Please replace it with your actual data file.\n",
            "Data loaded successfully!\n",
            "\n",
            "First 5 rows of the DataFrame:\n",
            "   col1 col2  col3\n",
            "0     1    A  10.5\n",
            "1     2    B  20.3\n",
            "2     3    A  15.0\n",
            "3     4    C  22.1\n",
            "4     5    B  18.7\n",
            "\n",
            "Information about the DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5 entries, 0 to 4\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   col1    5 non-null      int64  \n",
            " 1   col2    5 non-null      object \n",
            " 2   col3    5 non-null      float64\n",
            "dtypes: float64(1), int64(1), object(1)\n",
            "memory usage: 252.0+ bytes\n",
            "None\n",
            "\n",
            "Descriptive statistics of numerical columns:\n",
            "           col1       col3\n",
            "count  5.000000   5.000000\n",
            "mean   3.000000  17.320000\n",
            "std    1.581139   4.624067\n",
            "min    1.000000  10.500000\n",
            "25%    2.000000  15.000000\n",
            "50%    3.000000  18.700000\n",
            "75%    4.000000  20.300000\n",
            "max    5.000000  22.100000\n",
            "\n",
            "Shape of the DataFrame: (5, 3)\n",
            "\n",
            "Number of missing values per column:\n",
            "col1    0\n",
            "col2    0\n",
            "col3    0\n",
            "dtype: int64\n",
            "\n",
            "Unique values in categorical columns:\n",
            "- col2: 3 unique values (['A' 'B' 'C'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tG2LLFb4DSrf"
      },
      "source": [
        "### **Task 1**: Load and Inspect a Dataset\n",
        "\n",
        "*Instruction*: Load the `titanic.csv` dataset and display the first 5 rows. Show basic info and describe statistics of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Titanic dataset\n",
        "titanic_df = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')\n",
        "\n",
        "# Display the first 5 rows\n",
        "print(\"First 5 rows:\")\n",
        "print(titanic_df.head())\n",
        "\n",
        "# Display basic info of the dataset\n",
        "print(\"\\nBasic Info:\")\n",
        "print(titanic_df.info())\n",
        "\n",
        "# Display descriptive statistics of the dataset\n",
        "print(\"\\nDescriptive Statistics:\")\n",
        "print(titanic_df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqpHy0101miD",
        "outputId": "3c0c249e-8c92-4244-b005-3de44558e338"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "\n",
            "Basic Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            "None\n",
            "\n",
            "Descriptive Statistics:\n",
            "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
            "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
            "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
            "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
            "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
            "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
            "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
            "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
            "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
            "\n",
            "            Parch        Fare  \n",
            "count  891.000000  891.000000  \n",
            "mean     0.381594   32.204208  \n",
            "std      0.806057   49.693429  \n",
            "min      0.000000    0.000000  \n",
            "25%      0.000000    7.910400  \n",
            "50%      0.000000   14.454200  \n",
            "75%      0.000000   31.000000  \n",
            "max      6.000000  512.329200  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03CKwCBtDzRL"
      },
      "source": [
        "## Section 2: Handling Missing Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh1W_9m5DuzF"
      },
      "source": [
        "### **Task 2**: Identify and Handle Missing Data\n",
        "\n",
        "*Instruction*:\n",
        "\n",
        "\n",
        "\n",
        "*   Display the number of missing values per column.\n",
        "*   Fill missing `Age` values with the median.\n",
        "*   Drop the `Cabin` column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def handle_missing_data(df):\n",
        "    \"\"\"\n",
        "    Displays the number of missing values per column,\n",
        "    fills missing 'Age' values with the median, and\n",
        "    drops the 'Cabin' column.\n",
        "\n",
        "    Args:\n",
        "        df (pandas.DataFrame): The input DataFrame.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: The modified DataFrame.\n",
        "    \"\"\"\n",
        "    print(\"Number of missing values per column before handling:\")\n",
        "    print(df.isnull().sum())\n",
        "\n",
        "    # Fill missing 'Age' values with the median\n",
        "    median_age = df['Age'].median()\n",
        "    df['Age'].fillna(median_age, inplace=True)\n",
        "    print(\"\\nMissing 'Age' values filled with the median.\")\n",
        "\n",
        "    # Drop the 'Cabin' column\n",
        "    df.drop('Cabin', axis=1, inplace=True)\n",
        "    print(\"\\n'Cabin' column dropped.\")\n",
        "\n",
        "    print(\"\\nNumber of missing values per column after handling:\")\n",
        "    print(df.isnull().sum())\n",
        "\n",
        "    return df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a sample DataFrame with missing values for demonstration\n",
        "    data = {'PassengerId': [1, 2, 3, 4, 5, 6],\n",
        "            'Survived': [0, 1, 1, 0, 1, 0],\n",
        "            'Pclass': [3, 1, 3, 1, 3, 3],\n",
        "            'Name': ['Braund, Mr. Owen Harris', 'Cumings, Mrs. John Bradley (Florence Briggs Thayer)', 'Heikkinen, Miss. Laina', 'Futrelle, Mrs. Jacques Heath (Lily May Peel)', 'Allen, Mr. William Henry', 'Moran, Mr. James'],\n",
        "            'Sex': ['male', 'female', 'female', 'female', 'male', 'male'],\n",
        "            'Age': [22.0, 38.0, 26.0, 35.0, 35.0, np.nan],\n",
        "            'SibSp': [1, 1, 0, 1, 0, 0],\n",
        "            'Parch': [0, 0, 0, 0, 0, 0],\n",
        "            'Ticket': ['A/5 21171', 'PC 17599', 'STON/O2. 3101282', '113803', '373450', '330877'],\n",
        "            'Fare': [7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583],\n",
        "            'Cabin': [np.nan, 'C85', np.nan, 'C123', np.nan, np.nan],\n",
        "            'Embarked': ['S', 'C', 'S', 'S', 'S', 'Q']}\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    handled_df = handle_missing_data(df.copy()) # Use .copy() to avoid modifying the original DataFrame\n",
        "    print(\"\\nModified DataFrame (first 5 rows):\")\n",
        "    print(handled_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK1xWPn_xO4T",
        "outputId": "876e625f-a133-4871-c799-e4ae93927d14"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of missing values per column before handling:\n",
            "PassengerId    0\n",
            "Survived       0\n",
            "Pclass         0\n",
            "Name           0\n",
            "Sex            0\n",
            "Age            1\n",
            "SibSp          0\n",
            "Parch          0\n",
            "Ticket         0\n",
            "Fare           0\n",
            "Cabin          4\n",
            "Embarked       0\n",
            "dtype: int64\n",
            "\n",
            "Missing 'Age' values filled with the median.\n",
            "\n",
            "'Cabin' column dropped.\n",
            "\n",
            "Number of missing values per column after handling:\n",
            "PassengerId    0\n",
            "Survived       0\n",
            "Pclass         0\n",
            "Name           0\n",
            "Sex            0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Parch          0\n",
            "Ticket         0\n",
            "Fare           0\n",
            "Embarked       0\n",
            "dtype: int64\n",
            "\n",
            "Modified DataFrame (first 5 rows):\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         0       1   \n",
            "4            5         1       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Embarked  \n",
            "0      0         A/5 21171   7.2500        S  \n",
            "1      0          PC 17599  71.2833        C  \n",
            "2      0  STON/O2. 3101282   7.9250        S  \n",
            "3      0            113803  53.1000        S  \n",
            "4      0            373450   8.0500        S  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-17ca286b4c28>:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Age'].fillna(median_age, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVV1BgZvEE3a"
      },
      "source": [
        "## Section 3: Encoding Categorical Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opUK7Z7LEIr4"
      },
      "source": [
        "### **Task 3**: Convert Categorical to Numeric\n",
        "\n",
        "*Instruction*: Convert `Sex` and `Embarked` columns to numeric using:\n",
        "\n",
        "\n",
        "*   Label Encoding for `Sex`\n",
        "*   One-Hot Encoding for `Embarked`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UW3FMdjQEEl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29182ea8-83d9-422e-e5ed-ef8dc194ed3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "      Name     Sex Ticket Embarked\n",
            "0    Alice  female     A1        S\n",
            "1      Bob    male     B2        C\n",
            "2  Charlie  female     C3        S\n",
            "3    David    male     D4        Q\n",
            "4      Eve  female     E5        S\n",
            "Label Encoding applied to 'Sex' column.\n",
            "One-Hot Encoding applied to 'Embarked' column.\n",
            "\n",
            "DataFrame with Categorical Features Converted to Numeric:\n",
            "      Name Ticket  Sex_Encoded  Embarked_C  Embarked_Q  Embarked_S\n",
            "0    Alice     A1            0         0.0         0.0         1.0\n",
            "1      Bob     B2            1         1.0         0.0         0.0\n",
            "2  Charlie     C3            0         0.0         0.0         1.0\n",
            "3    David     D4            1         0.0         1.0         0.0\n",
            "4      Eve     E5            0         0.0         0.0         1.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "def convert_categorical_to_numeric(df):\n",
        "    \"\"\"\n",
        "    Converts the 'Sex' column to numeric using Label Encoding\n",
        "    and the 'Embarked' column to numeric using One-Hot Encoding.\n",
        "\n",
        "    Args:\n",
        "        df (pandas.DataFrame): The input DataFrame containing 'Sex' and 'Embarked' columns.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: A new DataFrame with the 'Sex' and 'Embarked' columns\n",
        "                          converted to numeric. The original columns are dropped.\n",
        "    \"\"\"\n",
        "    df_converted = df.copy()\n",
        "\n",
        "    # Label Encoding for 'Sex'\n",
        "    label_encoder = LabelEncoder()\n",
        "    df_converted['Sex_Encoded'] = label_encoder.fit_transform(df_converted['Sex'])\n",
        "    df_converted.drop('Sex', axis=1, inplace=True)\n",
        "    print(\"Label Encoding applied to 'Sex' column.\")\n",
        "\n",
        "    # One-Hot Encoding for 'Embarked'\n",
        "    onehot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "    encoded_embarked = onehot_encoder.fit_transform(df_converted[['Embarked']])\n",
        "    encoded_df = pd.DataFrame(encoded_embarked, columns=onehot_encoder.get_feature_names_out(['Embarked']))\n",
        "    df_converted = pd.concat([df_converted.drop('Embarked', axis=1), encoded_df], axis=1)\n",
        "    print(\"One-Hot Encoding applied to 'Embarked' column.\")\n",
        "\n",
        "    return df_converted\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a sample DataFrame with Sex and Embarked columns\n",
        "    data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
        "            'Sex': ['female', 'male', 'female', 'male', 'female'],\n",
        "            'Ticket': ['A1', 'B2', 'C3', 'D4', 'E5'],\n",
        "            'Embarked': ['S', 'C', 'S', 'Q', 'S']}\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    print(\"Original DataFrame:\")\n",
        "    print(df)\n",
        "\n",
        "    numeric_df = convert_categorical_to_numeric(df)\n",
        "\n",
        "    print(\"\\nDataFrame with Categorical Features Converted to Numeric:\")\n",
        "    print(numeric_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNO0DPi3EpgF"
      },
      "source": [
        "## Section 4: Feature Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W74DNGaJEtdj"
      },
      "source": [
        "### **Task 4**: Scale Numerical Features\n",
        "\n",
        "*Instruction*: Use StandardScaler to scale the Age and Fare columns.*italicized text*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def scale_numerical_features(df):\n",
        "    \"\"\"\n",
        "    Scales the 'Age' and 'Fare' columns of a DataFrame using StandardScaler.\n",
        "\n",
        "    Args:\n",
        "        df (pandas.DataFrame): The input DataFrame containing 'Age' and 'Fare' columns.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: A new DataFrame with the scaled 'Age' and 'Fare' columns,\n",
        "                          along with the original unscaled columns.\n",
        "    \"\"\"\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Make a copy to avoid modifying the original DataFrame directly\n",
        "    df_scaled = df.copy()\n",
        "\n",
        "    # Select the columns to scale\n",
        "    numerical_cols = ['Age', 'Fare']\n",
        "\n",
        "    # Check if the columns exist in the DataFrame\n",
        "    for col in numerical_cols:\n",
        "        if col not in df_scaled.columns:\n",
        "            print(f\"Warning: Column '{col}' not found in the DataFrame.\")\n",
        "            return None\n",
        "\n",
        "    # Scale the numerical columns\n",
        "    df_scaled[numerical_cols] = scaler.fit_transform(df_scaled[numerical_cols])\n",
        "\n",
        "    return df_scaled\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a sample DataFrame with Age and Fare columns\n",
        "    data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
        "            'Age': [25, 30, 22, 35, 28],\n",
        "            'Ticket': ['A1', 'B2', 'C3', 'D4', 'E5'],\n",
        "            'Fare': [10.50, 50.75, 7.90, 100.20, 25.00]}\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    print(\"Original DataFrame:\")\n",
        "    print(df)\n",
        "\n",
        "    scaled_df = scale_numerical_features(df)\n",
        "\n",
        "    if scaled_df is not None:\n",
        "        print(\"\\nDataFrame with Scaled 'Age' and 'Fare':\")\n",
        "        print(scaled_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LyRHtMIxzii",
        "outputId": "d118f02f-ad7c-4f53-adcf-6a93ce686886"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "      Name  Age Ticket    Fare\n",
            "0    Alice   25     A1   10.50\n",
            "1      Bob   30     B2   50.75\n",
            "2  Charlie   22     C3    7.90\n",
            "3    David   35     D4  100.20\n",
            "4      Eve   28     E5   25.00\n",
            "\n",
            "DataFrame with Scaled 'Age' and 'Fare':\n",
            "      Name       Age Ticket      Fare\n",
            "0    Alice -0.677631     A1 -0.828776\n",
            "1      Bob  0.451754     B2  0.347052\n",
            "2  Charlie -1.355262     C3 -0.904730\n",
            "3    David  1.581139     D4  1.791640\n",
            "4      Eve  0.000000     E5 -0.405186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFxPFagsE9mS"
      },
      "source": [
        "## Section 5: Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZwIOzHXFD1a"
      },
      "source": [
        "### **Task 5**: Build Preprocessing Pipeline\n",
        "\n",
        "*Instruction*: Using `ColumnTransformer` and `Pipeline` from `sklearn`, build a pipeline that:\n",
        "\n",
        "\n",
        "\n",
        "*   Imputes missing values\n",
        "*   Scales numeric data\n",
        "*   Encodes categorical data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Sample dataset with some missing values\n",
        "data = {\n",
        "    'Age': [22, 38, 26, 35, None],\n",
        "    'Fare': [7.25, 71.2833, 7.925, 53.1, 8.05],\n",
        "    'Sex': ['male', 'female', 'female', 'female', 'male'],\n",
        "    'Embarked': ['S', 'C', 'Q', 'S', None],\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Target variable (dummy)\n",
        "target = [0, 1, 1, 0, 0]  # Binary target for classification example\n",
        "\n",
        "# Split data into features (X) and target (y)\n",
        "X = df\n",
        "y = target\n",
        "\n",
        "# Define column types\n",
        "numeric_features = ['Age', 'Fare']\n",
        "categorical_features = ['Sex', 'Embarked']\n",
        "\n",
        "# Create preprocessing steps for numeric features (impute, then scale)\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values with mean\n",
        "    ('scaler', StandardScaler())  # Scale numeric features\n",
        "])\n",
        "\n",
        "# Create preprocessing steps for categorical features (impute, then encode)\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values with most frequent value\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # Encode categorical features\n",
        "])\n",
        "\n",
        "# Combine both transformers using ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Create a final pipeline with a classifier (RandomForest in this case)\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier())  # You can replace this with any model\n",
        "])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Output predictions\n",
        "print(\"Predictions:\", y_pred)\n",
        "\n",
        "# Optionally, you can check the transformed data\n",
        "transformed_data = pipeline.named_steps['preprocessor'].transform(X_test)\n",
        "print(\"Transformed Data (numeric and encoded categorical features):\")\n",
        "print(transformed_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qqK_In4ysiT",
        "outputId": "84db86b2-71c5-42a4-ccbc-5dd7baaa780c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [0]\n",
            "Transformed Data (numeric and encoded categorical features):\n",
            "[[2.19477621 2.65752716 1.         0.         0.         0.\n",
            "  0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-OY1jI5IaIB"
      },
      "source": [
        "## Section 6: Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeBCcr3RIi-8"
      },
      "source": [
        "### **Task 6**: Create a New Feature\n",
        "\n",
        "*Instruction*: Create a new feature `FamilySize` = `SibSp` + `Parch` + 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gSza6VScIakN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cb0fb68-32e5-4f2b-d337-d1e08c2a8fd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   SibSp  Parch  FamilySize\n",
            "0      1      0           2\n",
            "1      0      0           1\n",
            "2      3      1           5\n",
            "3      1      2           4\n",
            "4      0      0           1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame (assuming it's similar to Titanic dataset with 'SibSp' and 'Parch' columns)\n",
        "data = {\n",
        "    'SibSp': [1, 0, 3, 1, 0],\n",
        "    'Parch': [0, 0, 1, 2, 0]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Creating the new feature 'FamilySize'\n",
        "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
        "\n",
        "# Output the DataFrame\n",
        "print(df)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}