{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task 7: Introduction to Natural Language (Text) Processing"
      ],
      "metadata": {
        "id": "L982FdumDCVn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1: Setup and Sample Dataset"
      ],
      "metadata": {
        "id": "gk9AwRFXDO6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 1**: Import Libraries and Sample Data\n",
        "*Instruction*: Import the necessary libraries and define a sample dataset for sentiment classification."
      ],
      "metadata": {
        "id": "tG2LLFb4DSrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'text': [\n",
        "        'I love this movie. It was fantastic!',\n",
        "        'Terrible acting and horrible plot.',\n",
        "        'An excellent film with great characters.',\n",
        "        'Worst movie I have ever seen.',\n",
        "        'Absolutely wonderful! A must-watch.',\n",
        "        'It was okay, nothing special.',\n",
        "        'Bad movie, waste of time.',\n",
        "        'Pretty good, I liked it.',\n",
        "        'Not great, but not terrible.',\n",
        "        'Awful! Never again.'\n",
        "    ],\n",
        "    'label': [1, 0, 1, 0, 1, 1, 0, 1, 0, 0]  # 1 = positive, 0 = negative\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "G6YtbgenDSWH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "6d9d645d-bcae-4740-cbbb-c14f6b9bd553"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       text  label\n",
              "0      I love this movie. It was fantastic!      1\n",
              "1        Terrible acting and horrible plot.      0\n",
              "2  An excellent film with great characters.      1\n",
              "3             Worst movie I have ever seen.      0\n",
              "4       Absolutely wonderful! A must-watch.      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f68e7cd-b6b9-401a-a5c3-b12129457799\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I love this movie. It was fantastic!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Terrible acting and horrible plot.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>An excellent film with great characters.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Worst movie I have ever seen.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Absolutely wonderful! A must-watch.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f68e7cd-b6b9-401a-a5c3-b12129457799')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0f68e7cd-b6b9-401a-a5c3-b12129457799 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0f68e7cd-b6b9-401a-a5c3-b12129457799');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5b3a231f-c936-46bd-827a-87782c32907e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b3a231f-c936-46bd-827a-87782c32907e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5b3a231f-c936-46bd-827a-87782c32907e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Not great, but not terrible.\",\n          \"Terrible acting and horrible plot.\",\n          \"It was okay, nothing special.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2: Text Preprocessing"
      ],
      "metadata": {
        "id": "03CKwCBtDzRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 2**: Clean the Text\n",
        "\n",
        "*Instruction*: Lowercase the text, remove punctuation, stopwords, and tokenize the sentences.\n"
      ],
      "metadata": {
        "id": "oh1W_9m5DuzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import nltk\n",
        "\n",
        "# Assuming you have the 'cleaned_sentences' from the previous step\n",
        "# If not, you'll need to run the text cleaning code first.\n",
        "# For demonstration, let's create a sample cleaned_sentences list:\n",
        "cleaned_sentences = [['hello', 'sample', 'sentence', 'punctuation', 'common', 'words', 'remove'],\n",
        "                     ['quite', 'interesting']]\n",
        "\n",
        "# --- 1. Bag of Words (BoW) Vectorization ---\n",
        "# First, we need to flatten the list of lists of words back into a list of strings (sentences)\n",
        "# for the vectorizers.\n",
        "flat_cleaned_sentences = [\" \".join(sentence) for sentence in cleaned_sentences]\n",
        "\n",
        "# Initialize the CountVectorizer\n",
        "bow_vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the cleaned sentences\n",
        "bow_features = bow_vectorizer.fit_transform(flat_cleaned_sentences)\n",
        "\n",
        "# Get the feature names (words in the vocabulary)\n",
        "bow_feature_names = bow_vectorizer.get_feature_names_out()\n",
        "\n",
        "# --- Output for Bag of Words ---\n",
        "print(\"--- Bag of Words (BoW) Vectorization ---\")\n",
        "print(\"\\nVocabulary (Feature Names):\")\n",
        "print(bow_feature_names)\n",
        "\n",
        "print(\"\\nBoW Features (Sparse Matrix):\")\n",
        "print(bow_features)\n",
        "\n",
        "print(\"\\nBoW Features (Dense Array - for better readability, but be cautious with large datasets):\")\n",
        "print(bow_features.toarray())\n",
        "\n",
        "# --- 2. TF-IDF Vectorization ---\n",
        "# Initialize the TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the cleaned sentences\n",
        "tfidf_features = tfidf_vectorizer.fit_transform(flat_cleaned_sentences)\n",
        "\n",
        "# Get the feature names (words in the vocabulary)\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# --- Output for TF-IDF ---\n",
        "print(\"\\n\\n--- TF-IDF Vectorization ---\")\n",
        "print(\"\\nVocabulary (Feature Names):\")\n",
        "print(tfidf_feature_names)\n",
        "\n",
        "print(\"\\nTF-IDF Features (Sparse Matrix):\")\n",
        "print(tfidf_features)\n",
        "\n",
        "print(\"\\nTF-IDF Features (Dense Array - for better readability, but be cautious with large datasets):\")\n",
        "print(tfidf_features.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxkCBqsE9Lr0",
        "outputId": "5f2e110d-3175-472b-cd31-af730b4b3e00"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Bag of Words (BoW) Vectorization ---\n",
            "\n",
            "Vocabulary (Feature Names):\n",
            "['common' 'hello' 'interesting' 'punctuation' 'quite' 'remove' 'sample'\n",
            " 'sentence' 'words']\n",
            "\n",
            "BoW Features (Sparse Matrix):\n",
            "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
            "\twith 9 stored elements and shape (2, 9)>\n",
            "  Coords\tValues\n",
            "  (0, 1)\t1\n",
            "  (0, 6)\t1\n",
            "  (0, 7)\t1\n",
            "  (0, 3)\t1\n",
            "  (0, 0)\t1\n",
            "  (0, 8)\t1\n",
            "  (0, 5)\t1\n",
            "  (1, 4)\t1\n",
            "  (1, 2)\t1\n",
            "\n",
            "BoW Features (Dense Array - for better readability, but be cautious with large datasets):\n",
            "[[1 1 0 1 0 1 1 1 1]\n",
            " [0 0 1 0 1 0 0 0 0]]\n",
            "\n",
            "\n",
            "--- TF-IDF Vectorization ---\n",
            "\n",
            "Vocabulary (Feature Names):\n",
            "['common' 'hello' 'interesting' 'punctuation' 'quite' 'remove' 'sample'\n",
            " 'sentence' 'words']\n",
            "\n",
            "TF-IDF Features (Sparse Matrix):\n",
            "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 9 stored elements and shape (2, 9)>\n",
            "  Coords\tValues\n",
            "  (0, 1)\t0.3779644730092272\n",
            "  (0, 6)\t0.3779644730092272\n",
            "  (0, 7)\t0.3779644730092272\n",
            "  (0, 3)\t0.3779644730092272\n",
            "  (0, 0)\t0.3779644730092272\n",
            "  (0, 8)\t0.3779644730092272\n",
            "  (0, 5)\t0.3779644730092272\n",
            "  (1, 4)\t0.7071067811865476\n",
            "  (1, 2)\t0.7071067811865476\n",
            "\n",
            "TF-IDF Features (Dense Array - for better readability, but be cautious with large datasets):\n",
            "[[0.37796447 0.37796447 0.         0.37796447 0.         0.37796447\n",
            "  0.37796447 0.37796447 0.37796447]\n",
            " [0.         0.         0.70710678 0.         0.70710678 0.\n",
            "  0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 3: Text Vectorization"
      ],
      "metadata": {
        "id": "mVV1BgZvEE3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 3**: Convert Text to Numerical Features\n",
        "\n",
        "*Instruction*: Use both Bag of Words and TF-IDF vectorization to convert the cleaned text.\n"
      ],
      "metadata": {
        "id": "opUK7Z7LEIr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# Assume you have cleaned sentences as a list of strings\n",
        "# If your cleaned sentences are a list of lists of words,\n",
        "# uncomment and run the following to convert them:\n",
        "# cleaned_sentences_lists = [['hello', 'sample', 'sentence', 'punctuation', 'common', 'words', 'remove'],\n",
        "#                            ['quite', 'interesting']]\n",
        "# cleaned_sentences = [\" \".join(sentence) for sentence in cleaned_sentences_lists]\n",
        "\n",
        "# For demonstration, let's use some sample cleaned sentences as a list of strings\n",
        "cleaned_sentences = [\n",
        "    \"hello sample sentence punctuation common words remove\",\n",
        "    \"quite interesting\"\n",
        "]\n",
        "\n",
        "# --- Bag of Words (BoW) Vectorization ---\n",
        "# Initialize the CountVectorizer\n",
        "bow_vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the cleaned sentences\n",
        "bow_features = bow_vectorizer.fit_transform(cleaned_sentences)\n",
        "\n",
        "# Get the feature names (words in the vocabulary)\n",
        "bow_feature_names = bow_vectorizer.get_feature_names_out()\n",
        "\n",
        "# --- Output for Bag of Words ---\n",
        "print(\"--- Bag of Words (BoW) Vectorization ---\")\n",
        "print(\"\\nVocabulary (Feature Names):\")\n",
        "print(bow_feature_names)\n",
        "\n",
        "print(\"\\nBoW Features (Sparse Matrix):\")\n",
        "print(bow_features)\n",
        "\n",
        "print(\"\\nBoW Features (Dense Array - for better readability, but use .toarray() with caution on large datasets):\")\n",
        "print(bow_features.toarray())\n",
        "\n",
        "# --- TF-IDF Vectorization ---\n",
        "# Initialize the TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the cleaned sentences\n",
        "tfidf_features = tfidf_vectorizer.fit_transform(cleaned_sentences)\n",
        "\n",
        "# Get the feature names (words in the vocabulary)\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# --- Output for TF-IDF ---\n",
        "print(\"\\n\\n--- TF-IDF Vectorization ---\")\n",
        "print(\"\\nVocabulary (Feature Names):\")\n",
        "print(tfidf_feature_names)\n",
        "\n",
        "print(\"\\nTF-IDF Features (Sparse Matrix):\")\n",
        "print(tfidf_features)\n",
        "\n",
        "print(\"\\nTF-IDF Features (Dense Array - for better readability, but use .toarray() with caution on large datasets):\")\n",
        "print(tfidf_features.toarray())"
      ],
      "metadata": {
        "id": "UW3FMdjQEEl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4c4ec74-250d-4d6b-f2b4-3cf60b4fd77b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Bag of Words (BoW) Vectorization ---\n",
            "\n",
            "Vocabulary (Feature Names):\n",
            "['common' 'hello' 'interesting' 'punctuation' 'quite' 'remove' 'sample'\n",
            " 'sentence' 'words']\n",
            "\n",
            "BoW Features (Sparse Matrix):\n",
            "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
            "\twith 9 stored elements and shape (2, 9)>\n",
            "  Coords\tValues\n",
            "  (0, 1)\t1\n",
            "  (0, 6)\t1\n",
            "  (0, 7)\t1\n",
            "  (0, 3)\t1\n",
            "  (0, 0)\t1\n",
            "  (0, 8)\t1\n",
            "  (0, 5)\t1\n",
            "  (1, 4)\t1\n",
            "  (1, 2)\t1\n",
            "\n",
            "BoW Features (Dense Array - for better readability, but use .toarray() with caution on large datasets):\n",
            "[[1 1 0 1 0 1 1 1 1]\n",
            " [0 0 1 0 1 0 0 0 0]]\n",
            "\n",
            "\n",
            "--- TF-IDF Vectorization ---\n",
            "\n",
            "Vocabulary (Feature Names):\n",
            "['common' 'hello' 'interesting' 'punctuation' 'quite' 'remove' 'sample'\n",
            " 'sentence' 'words']\n",
            "\n",
            "TF-IDF Features (Sparse Matrix):\n",
            "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 9 stored elements and shape (2, 9)>\n",
            "  Coords\tValues\n",
            "  (0, 1)\t0.3779644730092272\n",
            "  (0, 6)\t0.3779644730092272\n",
            "  (0, 7)\t0.3779644730092272\n",
            "  (0, 3)\t0.3779644730092272\n",
            "  (0, 0)\t0.3779644730092272\n",
            "  (0, 8)\t0.3779644730092272\n",
            "  (0, 5)\t0.3779644730092272\n",
            "  (1, 4)\t0.7071067811865476\n",
            "  (1, 2)\t0.7071067811865476\n",
            "\n",
            "TF-IDF Features (Dense Array - for better readability, but use .toarray() with caution on large datasets):\n",
            "[[0.37796447 0.37796447 0.         0.37796447 0.         0.37796447\n",
            "  0.37796447 0.37796447 0.37796447]\n",
            " [0.         0.         0.70710678 0.         0.70710678 0.\n",
            "  0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 4: Train a Classifier"
      ],
      "metadata": {
        "id": "GNO0DPi3EpgF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 4**: Sentiment Classification with Naive Bayes\n",
        "\n",
        "*Instruction*: Split the dataset, train a classifier using both feature sets, and evaluate the performance."
      ],
      "metadata": {
        "id": "W74DNGaJEtdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Assume you have the following from the previous step:\n",
        "# bow_features, tfidf_features, bow_feature_names, tfidf_feature_names\n",
        "\n",
        "# --- Create Sample Labels (REPLACE with your actual labels) ---\n",
        "# Make sure the number of labels matches the number of sentences\n",
        "labels = np.array([1, 0]) # 1 for positive, 0 for negative\n",
        "\n",
        "# --- 1. Sentiment Classification with Bag of Words Features ---\n",
        "\n",
        "print(\"--- Sentiment Classification with Bag of Words ---\")\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_bow, X_test_bow, y_train, y_test = train_test_split(\n",
        "    bow_features, labels, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Initialize the Naive Bayes classifier (MultinomialNB is suitable for text data)\n",
        "bow_model = MultinomialNB()\n",
        "\n",
        "# Train the model\n",
        "bow_model.fit(X_train_bow, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_bow = bow_model.predict(X_test_bow)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "bow_accuracy = accuracy_score(y_test, y_pred_bow)\n",
        "print(f\"Accuracy (BoW): {bow_accuracy}\")\n",
        "\n",
        "print(\"\\nClassification Report (BoW):\")\n",
        "print(classification_report(y_test, y_pred_bow))\n",
        "\n",
        "# --- 2. Sentiment Classification with TF-IDF Features ---\n",
        "\n",
        "print(\"\\n--- Sentiment Classification with TF-IDF ---\")\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(\n",
        "    tfidf_features, labels, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Initialize the Naive Bayes classifier (MultinomialNB is suitable for text data)\n",
        "tfidf_model = MultinomialNB()\n",
        "\n",
        "# Train the model\n",
        "tfidf_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_tfidf = tfidf_model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "tfidf_accuracy = accuracy_score(y_test, y_pred_tfidf)\n",
        "print(f\"Accuracy (TF-IDF): {tfidf_accuracy}\")\n",
        "\n",
        "print(\"\\nClassification Report (TF-IDF):\")\n",
        "print(classification_report(y_test, y_pred_tfidf))"
      ],
      "metadata": {
        "id": "aM8iWEAXEOmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5cc00a0-9be2-46db-8690-5f6f8b43eb80"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Sentiment Classification with Bag of Words ---\n",
            "Accuracy (BoW): 0.0\n",
            "\n",
            "Classification Report (BoW):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       1.0\n",
            "           1       0.00      0.00      0.00       0.0\n",
            "\n",
            "    accuracy                           0.00       1.0\n",
            "   macro avg       0.00      0.00      0.00       1.0\n",
            "weighted avg       0.00      0.00      0.00       1.0\n",
            "\n",
            "\n",
            "--- Sentiment Classification with TF-IDF ---\n",
            "Accuracy (TF-IDF): 0.0\n",
            "\n",
            "Classification Report (TF-IDF):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       1.0\n",
            "           1       0.00      0.00      0.00       0.0\n",
            "\n",
            "    accuracy                           0.00       1.0\n",
            "   macro avg       0.00      0.00      0.00       1.0\n",
            "weighted avg       0.00      0.00      0.00       1.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 5: Mini Challenge â€“ Classify Your Own Text"
      ],
      "metadata": {
        "id": "yFxPFagsE9mS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 5**:  User Input Prediction\n",
        "\n",
        "*Instruction*: Write a function that allows the user to enter a text and receive a prediction from the trained model.\n"
      ],
      "metadata": {
        "id": "IZwIOzHXFD1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import numpy as np\n",
        "\n",
        "# Download necessary NLTK resources if not already downloaded\n",
        "try:\n",
        "    stopwords.words('english')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "try:\n",
        "    sent_tokenize(\"This is a test.\")\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Cleans the input text by:\n",
        "    1. Converting to lowercase.\n",
        "    2. Removing punctuation.\n",
        "    3. Removing stopwords.\n",
        "    \"\"\"\n",
        "    text_lower = text.lower()\n",
        "    text_no_punctuation = ''.join([char for char in text_lower if char not in string.punctuation])\n",
        "    words = text_no_punctuation.split()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words_no_stopwords = [word for word in words if word not in stop_words]\n",
        "    return \" \".join(words_no_stopwords)\n",
        "\n",
        "# --- Simulate a Trained Model and Vectorizer ---\n",
        "# In a real application, you would load these from saved files.\n",
        "# For this example, we'll train a very simple one on some dummy data.\n",
        "\n",
        "# Dummy training data\n",
        "train_texts = [\n",
        "    \"This movie is fantastic!\",\n",
        "    \"I really enjoyed the performance.\",\n",
        "    \"The service was terrible.\",\n",
        "    \"What a disappointing experience.\",\n",
        "    \"Highly recommended to everyone.\",\n",
        "    \"Absolutely the worst.\"\n",
        "]\n",
        "train_labels = np.array([1, 1, 0, 0, 1, 0]) # 1 for positive, 0 for negative\n",
        "\n",
        "# Clean the training texts\n",
        "cleaned_train_texts = [clean_text(text) for text in train_texts]\n",
        "\n",
        "# Use TfidfVectorizer for this example\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(cleaned_train_texts)\n",
        "\n",
        "# Train a Multinomial Naive Bayes model\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_vectorized, train_labels)\n",
        "\n",
        "# Define the class labels\n",
        "class_labels = ['negative', 'positive']\n",
        "\n",
        "# --- Prediction Function ---\n",
        "\n",
        "def predict_sentiment(text, model, vectorizer, class_labels):\n",
        "    \"\"\"\n",
        "    Predicts the sentiment of the input text.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text from the user.\n",
        "        model: The trained sentiment classification model.\n",
        "        vectorizer: The fitted vectorizer.\n",
        "        class_labels (list): A list of strings representing the class labels.\n",
        "\n",
        "    Returns:\n",
        "        str: The predicted sentiment label.\n",
        "    \"\"\"\n",
        "    cleaned_text = clean_text(text)\n",
        "    text_vectorized = vectorizer.transform([cleaned_text])\n",
        "    prediction = model.predict(text_vectorized)\n",
        "    predicted_class_index = prediction[0]\n",
        "    predicted_class_label = class_labels[predicted_class_index]\n",
        "    return f\"The predicted sentiment is: {predicted_class_label}\"\n",
        "\n",
        "# --- Get User Input and Make Prediction ---\n",
        "\n",
        "# Code\n",
        "user_input = input(\"Enter the text you want to analyze: \")\n",
        "\n",
        "# Make the prediction\n",
        "predicted_sentiment = predict_sentiment(user_input, model, vectorizer, class_labels)\n",
        "\n",
        "# Output the prediction\n",
        "print(predicted_sentiment)\n",
        "\n",
        "# Text (Example Interactions)\n",
        "print(\"\\n--- Example Interactions ---\")\n",
        "\n",
        "# Example 1\n",
        "user_text_1 = \"I had a wonderful time at the party.\"\n",
        "prediction_1 = predict_sentiment(user_text_1, model, vectorizer, class_labels)\n",
        "print(f\"Input: '{user_text_1}' -> {prediction_1}\")\n",
        "\n",
        "# Example 2\n",
        "user_text_2 = \"This is absolutely the worst service I've ever received.\"\n",
        "prediction_2 = predict_sentiment(user_text_2, model, vectorizer, class_labels)\n",
        "print(f\"Input: '{user_text_2}' -> {prediction_2}\")\n",
        "\n",
        "# Example 3\n",
        "user_text_3 = \"It was okay, nothing special.\"\n",
        "prediction_3 = predict_sentiment(user_text_3, model, vectorizer, class_labels)\n",
        "print(f\"Input: '{user_text_3}' -> {prediction_3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DtNLqjbDfeC",
        "outputId": "f2b1209d-d91f-450e-edb2-17583393cffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}